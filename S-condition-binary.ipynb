{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report,accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import svm\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade gensim==3.8.3\n",
    "#!pip3 install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all three datasets\n",
    "trainFilePath = 'dataset/train2.tsv'\n",
    "testFilePath = 'dataset/test2.tsv'\n",
    "validationFilePath = 'dataset/val2.tsv'\n",
    "\n",
    "# add header to all three datasets\n",
    "df_train = pd.read_csv(trainFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
    "\n",
    "df_test = pd.read_csv(testFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
    "\n",
    "\n",
    "df_validation = pd.read_csv(validationFilePath, delimiter='\\t', names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"train-test-val\"] = 0\n",
    "df_test[\"train-test-val\"] = 1\n",
    "df_validation[\"train-test-val\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train,df_test,df_validation]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleaning(df,field):\n",
    "    df[field] = df[field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[field] = df[field].str.replace(r\"[^A-Za-z0-9]\", \" \")\n",
    "    df[field] = df[field].str.replace(r\"(),!?@\\'\\`\\\"\\_\\n\", \" \")\n",
    "    df[field] = df[field].str.replace(r\"@\", \"at\")\n",
    "    df[field] = df[field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[field] = df[field].str.replace(r\"http\", \"\")\n",
    "    df[field] = df[field].str.lower()\n",
    "    return df\n",
    "\n",
    "def dataPreprocessing(df):\n",
    "    df = df[df['ID'].notna()]\n",
    "    df = df[df['Barely True Cnt'].notna()]\n",
    "    df = df[df['False Cnt'].notna()]\n",
    "    df = df[df['Mostly True Cnt'].notna()]\n",
    "    df = df[df['Pants on Fire Cnt'].notna()]\n",
    "    df = df[df['Half True Cnt'].notna()]\n",
    "\n",
    "    df['ID'] = df['ID'].str.split(\".\", n = 1, expand = True) \n",
    "    \n",
    "    df = dataCleaning(df,'Statement')\n",
    "    df = dataCleaning(df,'Subject')\n",
    "    df = dataCleaning(df,'Speaker')\n",
    "    df = dataCleaning(df,'Job Title')\n",
    "    df = dataCleaning(df,'State')\n",
    "    df = dataCleaning(df,'Party')\n",
    "    df = dataCleaning(df,'Context')\n",
    "    df = dataCleaning(df,'Justification')    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = dataPreprocessing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_all[['Label','train-test-val']]\n",
    "encoder= ce.OrdinalEncoder(cols=['Label'],return_df=True,\n",
    "                           mapping=[{'col':'Label',\n",
    "'mapping':{'pants-fire':0,'false':0,'barely-true':0,'half-true':1,'mostly-true':1,'true':1}}])\n",
    "df_y = encoder.fit_transform(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 5655\n",
      "T: 7134\n",
      "OTHER: 0\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "t = 0\n",
    "o = 0\n",
    "\n",
    "for ind in df_y.index:\n",
    "    if(df_y['Label'][ind]==0):\n",
    "        f = f+1\n",
    "    elif(df_y['Label'][ind]==1):\n",
    "        t = t+1\n",
    "    else:\n",
    "        o = o+1\n",
    "\n",
    "print(\"F: \"+str(f))\n",
    "print(\"T: \"+str(t))\n",
    "print(\"OTHER: \"+str(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all[['Label','Statement','train-test-val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom Statement to Unigram tokens\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df[\"Unigrams\"] = df[\"Statement\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 13572\n"
     ]
    }
   ],
   "source": [
    "# create vocabulary\n",
    "allUnigrams = []\n",
    "for unigrams in df['Unigrams']:\n",
    "    for unigram in unigrams:\n",
    "        allUnigrams.append(unigram)\n",
    "vocabulary = sorted(list(set(allUnigrams)))\n",
    "print(\"Vocabulary Size: \"+str(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT to download pretrained word2vec \n",
    "\n",
    "# import gensim.downloader as api\n",
    "# path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "# print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = 'C:/Users/Nalin/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec(unigrams, generate_missing=False, k=300):\n",
    "    if len(unigrams)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [model[word] if word in model else np.random.rand(k) for word in unigrams]\n",
    "    else:\n",
    "        vectorized = [model[word] if word in model else np.zeros(k) for word in unigrams]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(df, generate_missing=False):\n",
    "    embeddings = df['Unigrams'].apply(lambda x: get_word2vec(x,generate_missing=generate_missing))\n",
    "    print(type(embeddings))\n",
    "    return list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_word2vec_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded_words = pd.DataFrame.from_records(embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded_words[\"train-test-val\"] = df[\"train-test-val\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12789, 301)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedded_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_embedded_words[df_embedded_words['train-test-val']==0]\n",
    "x_test = df_embedded_words[df_embedded_words['train-test-val']==1]\n",
    "x_val = df_embedded_words[df_embedded_words['train-test-val']==2]\n",
    "\n",
    "x_train.drop(['train-test-val'], axis = 1, inplace = True) \n",
    "x_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "x_val.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "\n",
    "y_train = df_y[df_y['train-test-val']==0]\n",
    "y_test = df_y[df_y['train-test-val']==1]\n",
    "y_val = df_y[df_y['train-test-val']==2]\n",
    "\n",
    "y_train.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_val.drop(['train-test-val'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train: 10238\n",
      "Y-Train: 10238\n",
      "X-Test: 1267\n",
      "Y-Test: 1267\n",
      "X-val: 1284\n",
      "Y-val: 1284\n"
     ]
    }
   ],
   "source": [
    "print(\"X-Train: \"+str(len(x_train)))\n",
    "print(\"Y-Train: \"+str(len(y_train)))\n",
    "print(\"X-Test: \"+str(len(x_test)))\n",
    "print(\"Y-Test: \"+str(len(y_test)))\n",
    "print(\"X-val: \"+str(len(x_val)))\n",
    "print(\"Y-val: \"+str(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', random_state=30,C=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(y_test,y_predict):\n",
    "    print(classification_report(y_test,y_predict))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_test,y_predict))\n",
    "    print(\"\\n Accuracy\")\n",
    "    print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.59      0.56       553\n",
      "           1       0.65      0.61      0.63       714\n",
      "\n",
      "    accuracy                           0.60      1267\n",
      "   macro avg       0.59      0.60      0.59      1267\n",
      "weighted avg       0.60      0.60      0.60      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[324 229]\n",
      " [281 433]]\n",
      "\n",
      " Accuracy\n",
      "0.5974743488555643\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       616\n",
      "           1       0.65      0.60      0.62       668\n",
      "\n",
      "    accuracy                           0.62      1284\n",
      "   macro avg       0.62      0.62      0.62      1284\n",
      "weighted avg       0.62      0.62      0.62      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[395 221]\n",
      " [265 403]]\n",
      "\n",
      " Accuracy\n",
      "0.6214953271028038\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf.fit(x_train,y_train)\n",
    "y_pred = rbf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.20      0.29       553\n",
      "           1       0.59      0.90      0.71       714\n",
      "\n",
      "    accuracy                           0.59      1267\n",
      "   macro avg       0.60      0.55      0.50      1267\n",
      "weighted avg       0.59      0.59      0.53      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[108 445]\n",
      " [ 72 642]]\n",
      "\n",
      " Accuracy\n",
      "0.5919494869771112\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.fit(x_train,y_train)\n",
    "y_pred = poly.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.31      0.41       553\n",
      "           1       0.61      0.84      0.71       714\n",
      "\n",
      "    accuracy                           0.61      1267\n",
      "   macro avg       0.60      0.57      0.56      1267\n",
      "weighted avg       0.60      0.61      0.58      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[172 381]\n",
      " [117 597]]\n",
      "\n",
      " Accuracy\n",
      "0.6069455406471981\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
