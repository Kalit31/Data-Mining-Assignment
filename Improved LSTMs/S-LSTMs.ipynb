{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S-LSTMs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NuojByGxLGJkDzy-Y2nMVM8QccTBeWvj",
      "authorship_tag": "ABX9TyOldfmQwLWlW8Ybjr+aZa6W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kalit31/Data-Mining-Assignment/blob/main/S-LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDskHV1HNKx8",
        "outputId": "7f5a21d0-80de-4d9e-90d2-098c7dad9a21"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFEQ2p5EOXj3"
      },
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback, TensorBoard\n",
        "from keras.layers import Input, Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, BatchNormalization, Flatten, Dense, Dropout, Reshape, Concatenate, Masking\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import Sequence, to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.backend import epsilon\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report,accuracy_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhiNJo_Wxe1o"
      },
      "source": [
        "**Import dataset** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vngMWE4eOdBT"
      },
      "source": [
        "trainFilePath = 'dataset/train2.tsv'\n",
        "testFilePath = 'dataset/test2.tsv'\n",
        "validationFilePath = 'dataset/val2.tsv'\n",
        "\n",
        "PATH = \"/content/drive/My Drive/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzjKQmKMOsHS"
      },
      "source": [
        "df_train = pd.read_csv(PATH+trainFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
        "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
        "\n",
        "df_test = pd.read_csv(PATH+testFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
        "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
        "\n",
        "\n",
        "df_validation = pd.read_csv(PATH+validationFilePath, delimiter='\\t', names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
        "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "1kwQPl_uO6Z7",
        "outputId": "d57065ef-2e15-4392-df42-acd72cb7a084"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Speaker</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>State</th>\n",
              "      <th>Party</th>\n",
              "      <th>Barely True Cnt</th>\n",
              "      <th>False Cnt</th>\n",
              "      <th>Half True Cnt</th>\n",
              "      <th>Mostly True Cnt</th>\n",
              "      <th>Pants on Fire Cnt</th>\n",
              "      <th>Context</th>\n",
              "      <th>Justification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2635.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a mailer</td>\n",
              "      <td>That's a premise that he fails to back up. Ann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a floor speech.</td>\n",
              "      <td>Surovell said the decline of coal \"started whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>324.json</td>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Denver</td>\n",
              "      <td>Obama said he would have voted against the ame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1123.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>a news release</td>\n",
              "      <td>The release may have a point that Mikulskis co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9028.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>an interview on CNN</td>\n",
              "      <td>Crist said that the economic \"turnaround start...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID  ...                                      Justification\n",
              "0   2635.json  ...  That's a premise that he fails to back up. Ann...\n",
              "1  10540.json  ...  Surovell said the decline of coal \"started whe...\n",
              "2    324.json  ...  Obama said he would have voted against the ame...\n",
              "3   1123.json  ...  The release may have a point that Mikulskis co...\n",
              "4   9028.json  ...  Crist said that the economic \"turnaround start...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BFLl-iwxowQ"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0DuhoQNVynS"
      },
      "source": [
        "def dataCleaning(df,field):\n",
        "    df[field] = df[field].str.replace(r\"@\\S+\", \"\")\n",
        "    df[field] = df[field].str.replace(r\"[^A-Za-z0-9]\", \" \")\n",
        "    df[field] = df[field].str.replace(r\"(),!?@\\'\\`\\\"\\_\\n\", \" \")\n",
        "    df[field] = df[field].str.replace(r\"@\", \"at\")\n",
        "    df[field] = df[field].str.replace(r\"http\\S+\", \"\")\n",
        "    df[field] = df[field].str.replace(r\"http\", \"\")\n",
        "    df[field] = df[field].str.lower()\n",
        "    return df\n",
        "\n",
        "def dataPreprocessing(df):\n",
        "    df = df[df['ID'].notna()]\n",
        "    df = df[df['Barely True Cnt'].notna()]\n",
        "    df = df[df['False Cnt'].notna()]\n",
        "    df = df[df['Mostly True Cnt'].notna()]\n",
        "    df = df[df['Pants on Fire Cnt'].notna()]\n",
        "    df = df[df['Half True Cnt'].notna()]\n",
        "\n",
        "    df['ID'] = df['ID'].str.split(\".\", n = 1, expand = True) \n",
        "    \n",
        "    df = dataCleaning(df,'Statement')\n",
        "    df = dataCleaning(df,'Subject')\n",
        "    df = dataCleaning(df,'Speaker')\n",
        "    df = dataCleaning(df,'Job Title')\n",
        "    df = dataCleaning(df,'State')\n",
        "    df = dataCleaning(df,'Party')\n",
        "    df = dataCleaning(df,'Context')\n",
        "    df = dataCleaning(df,'Justification')    \n",
        "    \n",
        "    le_multi = LabelEncoder()\n",
        "    df.loc[:, 'Multi Class Label'] = le_multi.fit_transform(df.Label)\n",
        "    print(\"Label assignments: \" + str({l: i for i, l in enumerate(le_multi.classes_)}))   \n",
        "    \n",
        "    df['Binary Label'] = df.Label.apply(lambda x: 1 if x in ['false','pants-fire','barely-true']  else 0)\n",
        "\n",
        "    df = df.fillna('None')\n",
        "\n",
        "    return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGuj3ylmqUp3",
        "outputId": "b2ee8589-7eab-4820-8fb6-6cd4ec7ac6ce"
      },
      "source": [
        "df_train = dataPreprocessing(df_train)\n",
        "df_validation = dataPreprocessing(df_validation)\n",
        "df_test = dataPreprocessing(df_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label assignments: {'barely-true': 0, 'false': 1, 'half-true': 2, 'mostly-true': 3, 'pants-fire': 4, 'true': 5}\n",
            "Label assignments: {'barely-true': 0, 'false': 1, 'half-true': 2, 'mostly-true': 3, 'pants-fire': 4, 'true': 5}\n",
            "Label assignments: {'barely-true': 0, 'false': 1, 'half-true': 2, 'mostly-true': 3, 'pants-fire': 4, 'true': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52paYI26xwrm"
      },
      "source": [
        "**Embed data fields**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_UcrJXoPaAx"
      },
      "source": [
        "t = Tokenizer()\n",
        "  \n",
        "def get_embeddings(data, max_length):\n",
        "  t.fit_on_texts(data)\n",
        "  encoded_docs = t.texts_to_sequences(data)\n",
        "  padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "  return padded_docs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpRf8WQBhF2J"
      },
      "source": [
        "def embed_fields(df):\n",
        "  return [np.asarray(get_embeddings(df['Statement'], 50)).astype(np.int32),np.asarray(get_embeddings(df['Subject'], 10)).astype(np.int32),np.asarray(get_embeddings(df['Context'], 25)).astype(np.int32),\n",
        "          np.asarray(get_embeddings(df['Speaker'], 5)).astype(np.int32),np.asarray(get_embeddings(df['Party'], 5)).astype(np.int32),np.asarray(get_embeddings(df['Job Title'], 20)).astype(np.int32),\n",
        "          np.asarray(get_embeddings(df['State'], 5)).astype(np.int32),np.asarray(get_embeddings(df['Justification'], 150)).astype(np.int32),embed_metadata(df)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF1GShBdPb66"
      },
      "source": [
        "train_stmt_x = get_embeddings(df_train['Statement'], 50)\n",
        "\n",
        "val_stmt_x = get_embeddings(df_validation['Statement'], 50)\n",
        "\n",
        "test_stmt_x = get_embeddings(df_test['Statement'], 50)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHdgS0zDiN1Q",
        "outputId": "6ab4b8b3-bfdf-4533-8929-782175ebff94"
      },
      "source": [
        "vocab_size = len(t.word_index) + 1\n",
        "print(\"VOCABULARY SIZE: \"+str(vocab_size))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VOCABULARY SIZE: 13573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYmNnyFPPdiW"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open(PATH + 'dataset/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2Jgnh4_iX1U"
      },
      "source": [
        "def create_embedding_matrix():\n",
        "  embedding_matrix = np.zeros((vocab_size, 100))\n",
        "  for word, i in t.word_index.items():\n",
        "\t  embedding_vector = embeddings_index.get(word)\n",
        "\t  if embedding_vector is not None:\n",
        "\t\t  embedding_matrix[i] = embedding_vector\n",
        "  return embedding_matrix"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__3TEv8jSvg"
      },
      "source": [
        "embedding_matrix = create_embedding_matrix()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkKrZp-nPikR"
      },
      "source": [
        "def get_features(input_length):\n",
        "  input_tensor = Input((input_length,))\n",
        "  X = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=input_length, trainable=False)(input_tensor)\n",
        "  X = Bidirectional(LSTM(32, return_sequences=True))(X)\n",
        "  X = Bidirectional(LSTM(16, return_sequences=True))(X)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(1024, activation='relu', kernel_regularizer=l2(0.0))(X)\n",
        "  X = Dropout(0.3)(X)\n",
        "  X = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(X)\n",
        "  X = Reshape((8,16))(X)\n",
        "  X = Conv1D(128,3, padding='same', activation='relu', kernel_regularizer=l2(0.0))(X)\n",
        "  X = MaxPooling1D(2)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Flatten()(X)\n",
        "  output_tensor = Dense(128, activation='relu', kernel_regularizer=l2(0.0))(X)\n",
        "  output_tensor = Dropout(0.3)(output_tensor)\n",
        "  return input_tensor, output_tensor"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-diFsqaKx8lz"
      },
      "source": [
        "**Binary Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kucs2eyIPmeH",
        "outputId": "6e39f90f-77b6-4c30-b891-172b38463587"
      },
      "source": [
        "stmt_input, stmt_ftrs = get_features(train_stmt_x.shape[1])\n",
        "\n",
        "out = Dense(1028, activation='relu', kernel_regularizer=l2(0.0))(stmt_ftrs)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Dense(256, activation='relu', kernel_regularizer=l2(0.0))(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Dense(2, activation='sigmoid')(out)\n",
        "model_binary = Model(inputs = [stmt_input], outputs = out)\n",
        "model_binary.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 50, 100)           1357300   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 50, 64)            34048     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 32)            10368     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 16)             0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 8, 128)            6272      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4, 128)            512       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1028)              132612    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1028)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               263424    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 3,641,338\n",
            "Trainable params: 2,283,782\n",
            "Non-trainable params: 1,357,556\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKrxijkUPolE"
      },
      "source": [
        "train_y = to_categorical(df_train['Binary Label'], 2)\n",
        "val_y = to_categorical(df_validation['Binary Label'], 2)\n",
        "test_y = to_categorical(df_test['Binary Label'], 2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFuNIIyOPtT0"
      },
      "source": [
        "stop = EarlyStopping(monitor=\"val_acc\", patience=20, mode=\"max\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_acc\", factor=0.1, patience=10, min_lr=1e-6, verbose=1, mode=\"max\")\n",
        "optimizer = Adam(lr = 0.001)\n",
        "model_binary.compile(optimizer, loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXXX_-CFPxV4",
        "outputId": "8c53be35-e6ee-4aa5-92f8-7101ab86fe30"
      },
      "source": [
        "model_binary.fit([train_stmt_x], train_y,\n",
        "          epochs=10, verbose=1, validation_data=([val_stmt_x], val_y), callbacks=[reduce_lr, stop])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "320/320 [==============================] - 44s 22ms/step - loss: 1.3844 - acc: 0.5565 - val_loss: 0.7052 - val_acc: 0.5319\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.6915 - acc: 0.5559 - val_loss: 0.6920 - val_acc: 0.5522\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.6841 - acc: 0.5689 - val_loss: 0.6830 - val_acc: 0.5639\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 0.6774 - acc: 0.5897 - val_loss: 0.6873 - val_acc: 0.5358\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 0.6689 - acc: 0.5980 - val_loss: 0.6890 - val_acc: 0.5530\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 0.6658 - acc: 0.5980 - val_loss: 0.6959 - val_acc: 0.5389\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 0.6587 - acc: 0.6036 - val_loss: 0.7025 - val_acc: 0.5296\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.6506 - acc: 0.6258 - val_loss: 0.8001 - val_acc: 0.5327\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 0.6364 - acc: 0.6411 - val_loss: 0.6841 - val_acc: 0.5537\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 0.6294 - acc: 0.6592 - val_loss: 0.7017 - val_acc: 0.5374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f67304ffc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7b8zjilQMd4",
        "outputId": "035708a9-636e-4c25-ec39-7e8a781143c5"
      },
      "source": [
        "val_loss, val_acc = model_binary.evaluate([val_stmt_x], val_y,\n",
        "                                   verbose=1)\n",
        "print('Validation Accuracy: %f' % (val_acc))\n",
        "test_loss, test_acc = model_binary.evaluate([test_stmt_x],\n",
        "                                     test_y, verbose=1)\n",
        "print('Test Accuracy: %f' % (test_acc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 8ms/step - loss: 0.7017 - acc: 0.5374\n",
            "Validation Accuracy: 0.537383\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.7108 - acc: 0.5170\n",
            "Test Accuracy: 0.516969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGiHGrHTyOl9"
      },
      "source": [
        "**Multi class classification model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bm6qKc6TR6J"
      },
      "source": [
        "train_y = to_categorical(df_train['Multi Class Label'], 6)\n",
        "val_y = to_categorical(df_validation['Multi Class Label'], 6)\n",
        "test_y = to_categorical(df_test['Multi Class Label'], 6)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "681wsif3vHbe",
        "outputId": "30e0dd1a-9e04-489d-bd96-bafbc58831ff"
      },
      "source": [
        "stmt_input, stmt_ftrs = get_features(train_stmt_x.shape[1])\n",
        "\n",
        "out = Dense(1028, activation='relu', kernel_regularizer=l2(0.0))(stmt_ftrs)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Dense(256, activation='relu', kernel_regularizer=l2(0.0))(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Dense(6, activation='softmax')(out)\n",
        "model_multi = Model(inputs = [stmt_input], outputs = out)\n",
        "model_multi.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 50, 100)           1357300   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 50, 64)            34048     \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 50, 32)            10368     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 8, 16)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 8, 128)            6272      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 128)            512       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1028)              132612    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1028)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               263424    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 3,642,366\n",
            "Trainable params: 2,284,810\n",
            "Non-trainable params: 1,357,556\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Dz2T_2vRYx"
      },
      "source": [
        "stop = EarlyStopping(monitor=\"val_acc\", patience=20, mode=\"max\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_acc\", factor=0.1, patience=10, min_lr=1e-6, verbose=1, mode=\"max\")\n",
        "optimizer = Adam(lr = 0.001)\n",
        "model_multi.compile(optimizer, loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEnz0xU7vYCs",
        "outputId": "3797177d-557e-4546-a265-1718451a3174"
      },
      "source": [
        "model_multi.fit([train_stmt_x], train_y,\n",
        "          epochs=10, verbose=1, validation_data=([val_stmt_x], val_y), callbacks=[reduce_lr, stop])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "320/320 [==============================] - 12s 21ms/step - loss: 1.0494 - acc: 0.1904 - val_loss: 0.4867 - val_acc: 0.2048\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.4528 - acc: 0.2045 - val_loss: 0.4465 - val_acc: 0.2329\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.4482 - acc: 0.2090 - val_loss: 0.4444 - val_acc: 0.2321\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.4452 - acc: 0.2139 - val_loss: 0.4459 - val_acc: 0.2352\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.4437 - acc: 0.2285 - val_loss: 0.4462 - val_acc: 0.1931\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 0.4449 - acc: 0.2167 - val_loss: 0.4459 - val_acc: 0.2150\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.4402 - acc: 0.2342 - val_loss: 0.4486 - val_acc: 0.2220\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.4391 - acc: 0.2479 - val_loss: 0.4491 - val_acc: 0.2188\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.4361 - acc: 0.2642 - val_loss: 0.4631 - val_acc: 0.1526\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 0.4315 - acc: 0.2661 - val_loss: 0.4569 - val_acc: 0.2009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f672ae53850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqqnSEocvbtJ",
        "outputId": "317134ca-2e1b-48b3-d68e-c6736a026477"
      },
      "source": [
        "val_loss, val_acc = model_multi.evaluate([val_stmt_x], val_y,\n",
        "                                   verbose=1)\n",
        "print('Validation Accuracy: %f' % (val_acc))\n",
        "test_loss, test_acc = model_multi.evaluate([test_stmt_x],\n",
        "                                     test_y, verbose=1)\n",
        "print('Test Accuracy: %f' % (test_acc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 7ms/step - loss: 0.4569 - acc: 0.2009\n",
            "Validation Accuracy: 0.200935\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4544 - acc: 0.2139\n",
            "Test Accuracy: 0.213891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qp_x50AwpOQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}