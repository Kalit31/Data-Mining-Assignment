{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SJ-LSTMs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NuojByGxLGJkDzy-Y2nMVM8QccTBeWvj",
      "authorship_tag": "ABX9TyN+mY17r1hA+EL2+VgGTM/n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kalit31/Data-Mining-Assignment/blob/main/SJ-LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDskHV1HNKx8",
        "outputId": "59e95306-3194-4fdc-d879-0c2f34c5516f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFEQ2p5EOXj3"
      },
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback, TensorBoard\n",
        "from keras.layers import Input, Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, BatchNormalization, Flatten, Dense, Dropout, Reshape, Concatenate, Masking\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import Sequence, to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.backend import epsilon\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report,accuracy_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhiNJo_Wxe1o"
      },
      "source": [
        "**Import dataset** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vngMWE4eOdBT"
      },
      "source": [
        "trainFilePath = 'dataset/train2.tsv'\n",
        "testFilePath = 'dataset/test2.tsv'\n",
        "validationFilePath = 'dataset/val2.tsv'\n",
        "\n",
        "PATH = \"/content/drive/My Drive/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzjKQmKMOsHS"
      },
      "source": [
        "df_train = pd.read_csv(PATH+trainFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
        "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
        "\n",
        "df_test = pd.read_csv(PATH+testFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
        "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
        "\n",
        "\n",
        "df_validation = pd.read_csv(PATH+validationFilePath, delimiter='\\t', names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
        "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "1kwQPl_uO6Z7",
        "outputId": "349ed123-2cb8-416e-b151-5c4bc52ce9f4"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Speaker</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>State</th>\n",
              "      <th>Party</th>\n",
              "      <th>Barely True Cnt</th>\n",
              "      <th>False Cnt</th>\n",
              "      <th>Half True Cnt</th>\n",
              "      <th>Mostly True Cnt</th>\n",
              "      <th>Pants on Fire Cnt</th>\n",
              "      <th>Context</th>\n",
              "      <th>Justification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2635.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a mailer</td>\n",
              "      <td>That's a premise that he fails to back up. Ann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a floor speech.</td>\n",
              "      <td>Surovell said the decline of coal \"started whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>324.json</td>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Denver</td>\n",
              "      <td>Obama said he would have voted against the ame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1123.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>a news release</td>\n",
              "      <td>The release may have a point that Mikulskis co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9028.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>an interview on CNN</td>\n",
              "      <td>Crist said that the economic \"turnaround start...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID  ...                                      Justification\n",
              "0   2635.json  ...  That's a premise that he fails to back up. Ann...\n",
              "1  10540.json  ...  Surovell said the decline of coal \"started whe...\n",
              "2    324.json  ...  Obama said he would have voted against the ame...\n",
              "3   1123.json  ...  The release may have a point that Mikulskis co...\n",
              "4   9028.json  ...  Crist said that the economic \"turnaround start...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BFLl-iwxowQ"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0DuhoQNVynS"
      },
      "source": [
        "def dataCleaning(df,field):\n",
        "    df[field] = df[field].str.replace(r\"@\\S+\", \"\")\n",
        "    df[field] = df[field].str.replace(r\"[^A-Za-z0-9]\", \" \")\n",
        "    df[field] = df[field].str.replace(r\"(),!?@\\'\\`\\\"\\_\\n\", \" \")\n",
        "    df[field] = df[field].str.replace(r\"@\", \"at\")\n",
        "    df[field] = df[field].str.replace(r\"http\\S+\", \"\")\n",
        "    df[field] = df[field].str.replace(r\"http\", \"\")\n",
        "    df[field] = df[field].str.lower()\n",
        "    return df\n",
        "\n",
        "def dataPreprocessing(df):\n",
        "    df = df[df['ID'].notna()]\n",
        "    df = df[df['Barely True Cnt'].notna()]\n",
        "    df = df[df['False Cnt'].notna()]\n",
        "    df = df[df['Mostly True Cnt'].notna()]\n",
        "    df = df[df['Pants on Fire Cnt'].notna()]\n",
        "    df = df[df['Half True Cnt'].notna()]\n",
        "\n",
        "    df['ID'] = df['ID'].str.split(\".\", n = 1, expand = True) \n",
        "    \n",
        "    df = dataCleaning(df,'Statement')\n",
        "    df = dataCleaning(df,'Subject')\n",
        "    df = dataCleaning(df,'Speaker')\n",
        "    df = dataCleaning(df,'Job Title')\n",
        "    df = dataCleaning(df,'State')\n",
        "    df = dataCleaning(df,'Party')\n",
        "    df = dataCleaning(df,'Context')\n",
        "    df = dataCleaning(df,'Justification')    \n",
        "    \n",
        "    le_multi = LabelEncoder()\n",
        "    df.loc[:, 'Multi Class Label'] = le_multi.fit_transform(df.Label)\n",
        "    print(\"Label assignments: \" + str({l: i for i, l in enumerate(le_multi.classes_)}))   \n",
        "    \n",
        "    df['Binary Label'] = df.Label.apply(lambda x: 1 if x in ['false','pants-fire','barely-true']  else 0)\n",
        "\n",
        "    df = df.fillna('None')\n",
        "\n",
        "    return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGuj3ylmqUp3",
        "outputId": "88f4e56b-972f-4cd5-953a-40838f60d5bd"
      },
      "source": [
        "df_train = dataPreprocessing(df_train)\n",
        "df_validation = dataPreprocessing(df_validation)\n",
        "df_test = dataPreprocessing(df_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label assignments: {'barely-true': 0, 'false': 1, 'half-true': 2, 'mostly-true': 3, 'pants-fire': 4, 'true': 5}\n",
            "Label assignments: {'barely-true': 0, 'false': 1, 'half-true': 2, 'mostly-true': 3, 'pants-fire': 4, 'true': 5}\n",
            "Label assignments: {'barely-true': 0, 'false': 1, 'half-true': 2, 'mostly-true': 3, 'pants-fire': 4, 'true': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52paYI26xwrm"
      },
      "source": [
        "**Embed data fields**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_UcrJXoPaAx"
      },
      "source": [
        "t = Tokenizer()\n",
        "  \n",
        "def get_embeddings(data, max_length):\n",
        "  t.fit_on_texts(data)\n",
        "  encoded_docs = t.texts_to_sequences(data)\n",
        "  padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "  return padded_docs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpRf8WQBhF2J"
      },
      "source": [
        "def embed_fields(df):\n",
        "  return [np.asarray(get_embeddings(df['Statement'], 50)).astype(np.int32),np.asarray(get_embeddings(df['Subject'], 10)).astype(np.int32),np.asarray(get_embeddings(df['Context'], 25)).astype(np.int32),\n",
        "          np.asarray(get_embeddings(df['Speaker'], 5)).astype(np.int32),np.asarray(get_embeddings(df['Party'], 5)).astype(np.int32),np.asarray(get_embeddings(df['Job Title'], 20)).astype(np.int32),\n",
        "          np.asarray(get_embeddings(df['State'], 5)).astype(np.int32),np.asarray(get_embeddings(df['Justification'], 150)).astype(np.int32),embed_metadata(df)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF1GShBdPb66"
      },
      "source": [
        "train_stmt_x = get_embeddings(df_train['Statement'], 50)\n",
        "train_just_x = get_embeddings(df_train['Justification'], 150)\n",
        "\n",
        "val_stmt_x = get_embeddings(df_validation['Statement'], 50)\n",
        "val_just_x = get_embeddings(df_validation['Justification'], 150)\n",
        "\n",
        "test_stmt_x = get_embeddings(df_test['Statement'], 50)\n",
        "test_just_x = get_embeddings(df_test['Justification'], 150)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHdgS0zDiN1Q",
        "outputId": "3107b9c9-c6e1-4e5e-9190-747437ccc3b6"
      },
      "source": [
        "vocab_size = len(t.word_index) + 1\n",
        "print(\"VOCABULARY SIZE: \"+str(vocab_size))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VOCABULARY SIZE: 27387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYmNnyFPPdiW"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open(PATH + 'dataset/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2Jgnh4_iX1U"
      },
      "source": [
        "def create_embedding_matrix():\n",
        "  embedding_matrix = np.zeros((vocab_size, 100))\n",
        "  for word, i in t.word_index.items():\n",
        "\t  embedding_vector = embeddings_index.get(word)\n",
        "\t  if embedding_vector is not None:\n",
        "\t\t  embedding_matrix[i] = embedding_vector\n",
        "  return embedding_matrix"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__3TEv8jSvg"
      },
      "source": [
        "embedding_matrix = create_embedding_matrix()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkKrZp-nPikR"
      },
      "source": [
        "def get_features(input_length):\n",
        "  input_tensor = Input((input_length,))\n",
        "  X = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=input_length, trainable=False)(input_tensor)\n",
        "  X = Bidirectional(LSTM(32, return_sequences=True))(X)\n",
        "  X = Bidirectional(LSTM(16, return_sequences=True))(X)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(1024, activation='relu', kernel_regularizer=l2(0.0))(X)\n",
        "  X = Dropout(0.3)(X)\n",
        "  X = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(X)\n",
        "  X = Reshape((8,16))(X)\n",
        "  X = Conv1D(128,3, padding='same', activation='relu', kernel_regularizer=l2(0.0))(X)\n",
        "  X = MaxPooling1D(2)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Flatten()(X)\n",
        "  output_tensor = Dense(128, activation='relu', kernel_regularizer=l2(0.0))(X)\n",
        "  output_tensor = Dropout(0.3)(output_tensor)\n",
        "  return input_tensor, output_tensor"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-diFsqaKx8lz"
      },
      "source": [
        "**Binary Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kucs2eyIPmeH",
        "outputId": "a88af116-ef52-4d5a-f1a0-b69b7847efd2"
      },
      "source": [
        "stmt_input, stmt_ftrs = get_features(train_stmt_x.shape[1])\n",
        "just_input, just_ftrs = get_features(train_just_x.shape[1])\n",
        "\n",
        "out_1 = Concatenate()([stmt_ftrs, just_ftrs])\n",
        "out = Dense(1028, activation='relu', kernel_regularizer=l2(0.0))(out_1)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Dense(256, activation='relu', kernel_regularizer=l2(0.0))(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Dense(2, activation='sigmoid')(out)\n",
        "model_binary = Model(inputs = [stmt_input, just_input], outputs = out)\n",
        "model_binary.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 50, 100)      2738700     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 150, 100)     2738700     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 50, 64)       34048       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 150, 64)      34048       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 50, 32)       10368       bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 150, 32)      10368       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1600)         0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 4800)         0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         1639424     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1024)         4916224     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          131200      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          131200      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 8, 16)        0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 8, 16)        0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 8, 128)       6272        reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 8, 128)       6272        reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 4, 128)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 4, 128)       0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 4, 128)       512         max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 4, 128)       512         max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 512)          0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 512)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          65664       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 128)          65664       flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1028)         264196      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 1028)         0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 256)          263424      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 256)          0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            514         dropout_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 13,057,310\n",
            "Trainable params: 7,579,398\n",
            "Non-trainable params: 5,477,912\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKrxijkUPolE"
      },
      "source": [
        "train_y = to_categorical(df_train['Binary Label'], 2)\n",
        "val_y = to_categorical(df_validation['Binary Label'], 2)\n",
        "test_y = to_categorical(df_test['Binary Label'], 2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFuNIIyOPtT0"
      },
      "source": [
        "stop = EarlyStopping(monitor=\"val_acc\", patience=20, mode=\"max\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_acc\", factor=0.1, patience=10, min_lr=1e-6, verbose=1, mode=\"max\")\n",
        "optimizer = Adam(lr = 0.001)\n",
        "model_binary.compile(optimizer, loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXXX_-CFPxV4",
        "outputId": "a1e30cdc-ef24-4a3f-b06d-7e21eeeff0e7"
      },
      "source": [
        "model_binary.fit([train_stmt_x, train_just_x], train_y,\n",
        "          epochs=10, verbose=1, validation_data=([val_stmt_x, val_just_x], val_y), callbacks=[reduce_lr, stop])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "320/320 [==============================] - 57s 47ms/step - loss: 2.0670 - acc: 0.5526 - val_loss: 0.7050 - val_acc: 0.5389\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 12s 38ms/step - loss: 0.6957 - acc: 0.5625 - val_loss: 0.7189 - val_acc: 0.5210\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.6880 - acc: 0.5699 - val_loss: 0.7059 - val_acc: 0.5055\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.6750 - acc: 0.5953 - val_loss: 0.7027 - val_acc: 0.5171\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.6751 - acc: 0.5938 - val_loss: 0.7225 - val_acc: 0.4860\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 12s 38ms/step - loss: 0.6705 - acc: 0.6040 - val_loss: 0.7344 - val_acc: 0.5156\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 12s 38ms/step - loss: 0.6513 - acc: 0.6322 - val_loss: 0.7458 - val_acc: 0.5047\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.6460 - acc: 0.6381 - val_loss: 0.7398 - val_acc: 0.4961\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.6330 - acc: 0.6636 - val_loss: 0.7782 - val_acc: 0.5179\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.6088 - acc: 0.6847 - val_loss: 0.7534 - val_acc: 0.4759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3287e84b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7b8zjilQMd4",
        "outputId": "b7d581ca-6285-4dba-fc5a-4b1eb3c6836a"
      },
      "source": [
        "val_loss, val_acc = model_binary.evaluate([val_stmt_x, val_just_x], val_y,\n",
        "                                   verbose=1)\n",
        "print('Validation Accuracy: %f' % (val_acc))\n",
        "test_loss, test_acc = model_binary.evaluate([test_stmt_x, test_just_x],\n",
        "                                     test_y, verbose=1)\n",
        "print('Test Accuracy: %f' % (test_acc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7534 - acc: 0.4759\n",
            "Validation Accuracy: 0.475857\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 0.7468 - acc: 0.4925\n",
            "Test Accuracy: 0.492502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGiHGrHTyOl9"
      },
      "source": [
        "**Multi class classification model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bm6qKc6TR6J"
      },
      "source": [
        "train_y = to_categorical(df_train['Multi Class Label'], 6)\n",
        "val_y = to_categorical(df_validation['Multi Class Label'], 6)\n",
        "test_y = to_categorical(df_test['Multi Class Label'], 6)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "681wsif3vHbe",
        "outputId": "c80ea432-a45a-4569-bb0c-27076e1691cd"
      },
      "source": [
        "stmt_input, stmt_ftrs = get_features(train_stmt_x.shape[1])\n",
        "just_input, just_ftrs = get_features(train_just_x.shape[1])\n",
        "\n",
        "out_1 = Concatenate()([stmt_ftrs, just_ftrs])\n",
        "out = Dense(1028, activation='relu', kernel_regularizer=l2(0.0))(out_1)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Dense(256, activation='relu', kernel_regularizer=l2(0.0))(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Dense(6, activation='softmax')(out)\n",
        "model_multi = Model(inputs = [stmt_input, just_input], outputs = out)\n",
        "model_multi.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 50, 100)      2738700     input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 150, 100)     2738700     input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_8 (Bidirectional) (None, 50, 64)       34048       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_10 (Bidirectional (None, 150, 64)      34048       embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_9 (Bidirectional) (None, 50, 32)       10368       bidirectional_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_11 (Bidirectional (None, 150, 32)      10368       bidirectional_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 1600)         0           bidirectional_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 4800)         0           bidirectional_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 1024)         1639424     flatten_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 1024)         4916224     flatten_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 1024)         0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 1024)         0           dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 128)          131200      dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 128)          131200      dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 8, 16)        0           dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 8, 16)        0           dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 8, 128)       6272        reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 8, 128)       6272        reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 4, 128)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 4, 128)       0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 4, 128)       512         max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 4, 128)       512         max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 512)          0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 512)          0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 128)          65664       flatten_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 128)          65664       flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 128)          0           dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 128)          0           dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 1028)         264196      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 1028)         0           dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 256)          263424      dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 256)          0           dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 6)            1542        dropout_17[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 13,058,338\n",
            "Trainable params: 7,580,426\n",
            "Non-trainable params: 5,477,912\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Dz2T_2vRYx"
      },
      "source": [
        "stop = EarlyStopping(monitor=\"val_acc\", patience=20, mode=\"max\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_acc\", factor=0.1, patience=10, min_lr=1e-6, verbose=1, mode=\"max\")\n",
        "optimizer = Adam(lr = 0.001)\n",
        "model_multi.compile(optimizer, loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEnz0xU7vYCs",
        "outputId": "1f171e64-8df2-4509-8532-a388ff05a64e"
      },
      "source": [
        "model_multi.fit([train_stmt_x, train_just_x], train_y,\n",
        "          epochs=10, verbose=1, validation_data=([val_stmt_x, val_just_x], val_y), callbacks=[reduce_lr, stop])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "320/320 [==============================] - 24s 44ms/step - loss: 1.6353 - acc: 0.2015 - val_loss: 0.4949 - val_acc: 0.1955\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.4565 - acc: 0.2069 - val_loss: 0.4599 - val_acc: 0.2048\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.4526 - acc: 0.2076 - val_loss: 0.4515 - val_acc: 0.1963\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.4468 - acc: 0.2139 - val_loss: 0.4484 - val_acc: 0.1955\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.4448 - acc: 0.2327 - val_loss: 0.4522 - val_acc: 0.1963\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.4426 - acc: 0.2360 - val_loss: 0.4519 - val_acc: 0.1994\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.4411 - acc: 0.2476 - val_loss: 0.4590 - val_acc: 0.1939\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.4373 - acc: 0.2468 - val_loss: 0.4576 - val_acc: 0.1955\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 12s 38ms/step - loss: 0.4345 - acc: 0.2593 - val_loss: 0.4682 - val_acc: 0.1963\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 12s 38ms/step - loss: 0.4316 - acc: 0.2691 - val_loss: 0.4655 - val_acc: 0.1861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3293e80e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqqnSEocvbtJ",
        "outputId": "70b85741-a11f-417f-b57a-d206df8ce572"
      },
      "source": [
        "val_loss, val_acc = model_multi.evaluate([val_stmt_x, val_just_x], val_y,\n",
        "                                   verbose=1)\n",
        "print('Validation Accuracy: %f' % (val_acc))\n",
        "test_loss, test_acc = model_multi.evaluate([test_stmt_x, test_just_x],\n",
        "                                     test_y, verbose=1)\n",
        "print('Test Accuracy: %f' % (test_acc))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4655 - acc: 0.1861\n",
            "Validation Accuracy: 0.186137\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 0.4650 - acc: 0.1831\n",
            "Test Accuracy: 0.183110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qp_x50AwpOQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}