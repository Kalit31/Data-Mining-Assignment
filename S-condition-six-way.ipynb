{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report,accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import svm\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade gensim==3.8.3\n",
    "#!pip3 install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all three datasets\n",
    "trainFilePath = 'dataset/train2.tsv'\n",
    "testFilePath = 'dataset/test2.tsv'\n",
    "validationFilePath = 'dataset/val2.tsv'\n",
    "\n",
    "# add header to all three datasets\n",
    "df_train = pd.read_csv(trainFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
    "\n",
    "df_test = pd.read_csv(testFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
    "\n",
    "\n",
    "df_validation = pd.read_csv(validationFilePath, delimiter='\\t', names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"train-test-val\"] = 0\n",
    "df_test[\"train-test-val\"] = 1\n",
    "df_validation[\"train-test-val\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train,df_test,df_validation]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleaning(df,field):\n",
    "    df[field] = df[field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[field] = df[field].str.replace(r\"[^A-Za-z0-9]\", \" \")\n",
    "    df[field] = df[field].str.replace(r\"(),!?@\\'\\`\\\"\\_\\n\", \" \")\n",
    "    df[field] = df[field].str.replace(r\"@\", \"at\")\n",
    "    df[field] = df[field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[field] = df[field].str.replace(r\"http\", \"\")\n",
    "    df[field] = df[field].str.lower()\n",
    "    return df\n",
    "\n",
    "def dataPreprocessing(df):\n",
    "    df = df[df['ID'].notna()]\n",
    "    df = df[df['Barely True Cnt'].notna()]\n",
    "    df = df[df['False Cnt'].notna()]\n",
    "    df = df[df['Mostly True Cnt'].notna()]\n",
    "    df = df[df['Pants on Fire Cnt'].notna()]\n",
    "    df = df[df['Half True Cnt'].notna()]\n",
    "\n",
    "    df['ID'] = df['ID'].str.split(\".\", n = 1, expand = True) \n",
    "    \n",
    "    df = dataCleaning(df,'Statement')\n",
    "    df = dataCleaning(df,'Subject')\n",
    "    df = dataCleaning(df,'Speaker')\n",
    "    df = dataCleaning(df,'Job Title')\n",
    "    df = dataCleaning(df,'State')\n",
    "    df = dataCleaning(df,'Party')\n",
    "    df = dataCleaning(df,'Context')\n",
    "    df = dataCleaning(df,'Justification')    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = dataPreprocessing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_all[['Label','train-test-val']]\n",
    "encoder= ce.OrdinalEncoder(cols=['Label'],return_df=True,\n",
    "                           mapping=[{'col':'Label',\n",
    "'mapping':{'pants-fire':0,'false':1,'barely-true':2,'half-true':3,'mostly-true':4,'true':5}}])\n",
    "df_y = encoder.fit_transform(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANTS: 1047\n",
      "F: 2505\n",
      "BT: 2103\n",
      "HT: 2627\n",
      "MT: 2454\n",
      "T: 2053\n",
      "OTHER: 0\n"
     ]
    }
   ],
   "source": [
    "pf = 0\n",
    "f = 0\n",
    "bt = 0\n",
    "ht = 0\n",
    "mt = 0\n",
    "t = 0\n",
    "o = 0\n",
    "\n",
    "for ind in df_y.index:\n",
    "    if(df_y['Label'][ind]==0):\n",
    "        pf = pf+1\n",
    "    elif(df_y['Label'][ind]==1):\n",
    "        f = f+1\n",
    "    elif(df_y['Label'][ind]==2):\n",
    "        bt = bt+1\n",
    "    elif(df_y['Label'][ind]==3):\n",
    "        ht = ht+1\n",
    "    elif(df_y['Label'][ind]==4):\n",
    "        mt = mt+1\n",
    "    elif(df_y['Label'][ind]==5):\n",
    "        t = t+1\n",
    "    else:\n",
    "        o = o+1\n",
    "\n",
    "print(\"PANTS: \"+str(pf))\n",
    "print(\"F: \"+str(f))\n",
    "print(\"BT: \"+str(bt))\n",
    "print(\"HT: \"+str(ht))\n",
    "print(\"MT: \"+str(mt))\n",
    "print(\"T: \"+str(t))\n",
    "print(\"OTHER: \"+str(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all[['Label','Statement','train-test-val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom Statement to Unigram tokens\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df[\"Unigrams\"] = df[\"Statement\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 13572\n"
     ]
    }
   ],
   "source": [
    "# create vocabulary\n",
    "allUnigrams = []\n",
    "for unigrams in df['Unigrams']:\n",
    "    for unigram in unigrams:\n",
    "        allUnigrams.append(unigram)\n",
    "vocabulary = sorted(list(set(allUnigrams)))\n",
    "print(\"Vocabulary Size: \"+str(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT to download pretrained word2vec \n",
    "\n",
    "# import gensim.downloader as api\n",
    "# path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "# print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec_path = 'C:/Users/Nalin/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "word2vec_path = '/home/kalit/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec(unigrams, generate_missing=False, k=300):\n",
    "    if len(unigrams)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [model[word] if word in model else np.random.rand(k) for word in unigrams]\n",
    "    else:\n",
    "        vectorized = [model[word] if word in model else np.zeros(k) for word in unigrams]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(df, generate_missing=False):\n",
    "    embeddings = df['Unigrams'].apply(lambda x: get_word2vec(x,generate_missing=generate_missing))\n",
    "    print(type(embeddings))\n",
    "    return list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_word2vec_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded_words = pd.DataFrame.from_records(embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded_words[\"train-test-val\"] = df[\"train-test-val\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12789, 301)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedded_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_embedded_words[df_embedded_words['train-test-val']==0]\n",
    "x_test = df_embedded_words[df_embedded_words['train-test-val']==1]\n",
    "x_val = df_embedded_words[df_embedded_words['train-test-val']==2]\n",
    "\n",
    "x_train.drop(['train-test-val'], axis = 1, inplace = True) \n",
    "x_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "x_val.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "\n",
    "y_train = df_y[df_y['train-test-val']==0]\n",
    "y_test = df_y[df_y['train-test-val']==1]\n",
    "y_val = df_y[df_y['train-test-val']==2]\n",
    "\n",
    "y_train.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_val.drop(['train-test-val'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train: 10238\n",
      "Y-Train: 10238\n",
      "X-Test: 1267\n",
      "Y-Test: 1267\n",
      "X-val: 1284\n",
      "Y-val: 1284\n"
     ]
    }
   ],
   "source": [
    "print(\"X-Train: \"+str(len(x_train)))\n",
    "print(\"Y-Train: \"+str(len(y_train)))\n",
    "print(\"X-Test: \"+str(len(x_test)))\n",
    "print(\"Y-Test: \"+str(len(y_test)))\n",
    "print(\"X-val: \"+str(len(x_val)))\n",
    "print(\"Y-val: \"+str(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', random_state=30)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(y_test,y_predict):\n",
    "    print(classification_report(y_test,y_predict))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_test,y_predict))\n",
    "    print(\"\\n Accuracy\")\n",
    "    print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.40      0.22        92\n",
      "           1       0.26      0.18      0.21       249\n",
      "           2       0.17      0.17      0.17       212\n",
      "           3       0.28      0.20      0.24       265\n",
      "           4       0.27      0.29      0.28       241\n",
      "           5       0.27      0.25      0.26       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.23      0.25      0.23      1267\n",
      "weighted avg       0.25      0.23      0.23      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[37  9 17 10  7 12]\n",
      " [57 45 50 27 44 26]\n",
      " [51 30 36 32 33 30]\n",
      " [35 39 50 54 58 29]\n",
      " [27 23 33 42 71 45]\n",
      " [32 30 23 25 46 52]]\n",
      "\n",
      " Accuracy\n",
      "0.23283346487766376\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.45      0.27       116\n",
      "           1       0.19      0.14      0.16       263\n",
      "           2       0.23      0.19      0.21       237\n",
      "           3       0.27      0.17      0.21       248\n",
      "           4       0.26      0.24      0.25       251\n",
      "           5       0.23      0.33      0.27       169\n",
      "\n",
      "    accuracy                           0.23      1284\n",
      "   macro avg       0.23      0.25      0.23      1284\n",
      "weighted avg       0.23      0.23      0.22      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[52 19 18  3  6 18]\n",
      " [83 36 47 31 30 36]\n",
      " [48 40 45 29 44 31]\n",
      " [34 45 38 43 53 35]\n",
      " [30 38 37 25 59 62]\n",
      " [23 14 13 27 37 55]]\n",
      "\n",
      " Accuracy\n",
      "0.22585669781931464\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf.fit(x_train,y_train)\n",
    "y_pred = rbf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        92\n",
      "           1       0.24      0.39      0.30       249\n",
      "           2       0.00      0.00      0.00       212\n",
      "           3       0.22      0.65      0.32       265\n",
      "           4       0.29      0.08      0.13       241\n",
      "           5       0.00      0.00      0.00       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.13      0.19      0.13      1267\n",
      "weighted avg       0.15      0.23      0.15      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[  0  45   0  43   4   0]\n",
      " [  0  97   0 145   7   0]\n",
      " [  0  72   0 133   7   0]\n",
      " [  0  83   0 172  10   0]\n",
      " [  0  48   0 173  20   0]\n",
      " [  0  57   0 131  20   0]]\n",
      "\n",
      " Accuracy\n",
      "0.2280978689818469\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       116\n",
      "           1       0.28      0.43      0.34       263\n",
      "           2       0.00      0.00      0.00       237\n",
      "           3       0.21      0.66      0.31       248\n",
      "           4       0.31      0.10      0.16       251\n",
      "           5       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.24      1284\n",
      "   macro avg       0.13      0.20      0.13      1284\n",
      "weighted avg       0.16      0.24      0.16      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[  0  59   0  55   2   0]\n",
      " [  0 112   0 139  12   0]\n",
      " [  0  73   0 156   8   0]\n",
      " [  0  67   0 164  17   0]\n",
      " [  0  58   0 167  26   0]\n",
      " [  0  36   0 115  18   0]]\n",
      "\n",
      " Accuracy\n",
      "0.235202492211838\n"
     ]
    }
   ],
   "source": [
    "y_pred = rbf.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.fit(x_train,y_train)\n",
    "y_pred = poly.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.04      0.07        92\n",
      "           1       0.28      0.28      0.28       249\n",
      "           2       0.26      0.12      0.17       212\n",
      "           3       0.24      0.48      0.32       265\n",
      "           4       0.26      0.32      0.29       241\n",
      "           5       0.21      0.07      0.11       208\n",
      "\n",
      "    accuracy                           0.25      1267\n",
      "   macro avg       0.23      0.22      0.21      1267\n",
      "weighted avg       0.24      0.25      0.23      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[  4  27  11  33  12   5]\n",
      " [  7  70  22  85  53  12]\n",
      " [  4  45  26  91  35  11]\n",
      " [  4  47  24 127  56   7]\n",
      " [  3  25   6 108  77  22]\n",
      " [  5  39  12  77  60  15]]\n",
      "\n",
      " Accuracy\n",
      "0.2517758484609313\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.07      0.11       116\n",
      "           1       0.30      0.30      0.30       263\n",
      "           2       0.23      0.09      0.13       237\n",
      "           3       0.23      0.52      0.32       248\n",
      "           4       0.24      0.24      0.24       251\n",
      "           5       0.23      0.11      0.15       169\n",
      "\n",
      "    accuracy                           0.25      1284\n",
      "   macro avg       0.25      0.22      0.21      1284\n",
      "weighted avg       0.25      0.25      0.22      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[  8  40  10  45   9   4]\n",
      " [ 11  78  24  94  40  16]\n",
      " [  6  45  21 112  41  12]\n",
      " [  0  36  17 129  55  11]\n",
      " [  1  45  12 110  61  22]\n",
      " [  4  18   9  66  53  19]]\n",
      "\n",
      " Accuracy\n",
      "0.24610591900311526\n"
     ]
    }
   ],
   "source": [
    "y_pred = poly.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
