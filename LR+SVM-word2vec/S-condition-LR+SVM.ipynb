{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report,accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import torch\n",
    "from torchtext import data, datasets, vocab, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade gensim==3.8.3\n",
    "#!pip3 install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all three datasets\n",
    "trainFilePath = '../dataset/train2.tsv'\n",
    "testFilePath = '../dataset/test2.tsv'\n",
    "validationFilePath = '../dataset/val2.tsv'\n",
    "\n",
    "# add header to all three datasets\n",
    "df_train = pd.read_csv(trainFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
    "\n",
    "df_test = pd.read_csv(testFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
    "\n",
    "\n",
    "df_validation = pd.read_csv(validationFilePath, delimiter='\\t', names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"train-test-val\"] = 0\n",
    "df_test[\"train-test-val\"] = 1\n",
    "df_validation[\"train-test-val\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge datasets, seperate while training the model\n",
    "df_all = pd.concat([df_train,df_test,df_validation]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Barely True Cnt</th>\n",
       "      <th>False Cnt</th>\n",
       "      <th>Half True Cnt</th>\n",
       "      <th>Mostly True Cnt</th>\n",
       "      <th>Pants on Fire Cnt</th>\n",
       "      <th>Context</th>\n",
       "      <th>Justification</th>\n",
       "      <th>train-test-val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>That's a premise that he fails to back up. Ann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "      <td>Surovell said the decline of coal \"started whe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Obama said he would have voted against the ame...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "      <td>The release may have a point that Mikulskis co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "      <td>Crist said that the economic \"turnaround start...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID        Label                                          Statement  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              Subject         Speaker             Job Title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      State       Party  Barely True Cnt  False Cnt  Half True Cnt  \\\n",
       "0     Texas  republican              0.0        1.0            0.0   \n",
       "1  Virginia    democrat              0.0        0.0            1.0   \n",
       "2  Illinois    democrat             70.0       71.0          160.0   \n",
       "3       NaN        none              7.0       19.0            3.0   \n",
       "4   Florida    democrat             15.0        9.0           20.0   \n",
       "\n",
       "   Mostly True Cnt  Pants on Fire Cnt              Context  \\\n",
       "0              0.0                0.0             a mailer   \n",
       "1              1.0                0.0      a floor speech.   \n",
       "2            163.0                9.0               Denver   \n",
       "3              5.0               44.0       a news release   \n",
       "4             19.0                2.0  an interview on CNN   \n",
       "\n",
       "                                       Justification  train-test-val  \n",
       "0  That's a premise that he fails to back up. Ann...               0  \n",
       "1  Surovell said the decline of coal \"started whe...               0  \n",
       "2  Obama said he would have voted against the ame...               0  \n",
       "3  The release may have a point that Mikulskis co...               0  \n",
       "4  Crist said that the economic \"turnaround start...               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Remove all the rows having NAs. Clean the text. Encode multiclass and binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleaning(df,field):\n",
    "    df[field] = df[field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[field] = df[field].str.replace(r\"[^A-Za-z0-9]\", \" \")\n",
    "    df[field] = df[field].str.replace(r\"(),!?@\\'\\`\\\"\\_\\n\", \" \")\n",
    "    df[field] = df[field].str.replace(r\"@\", \"at\")\n",
    "    df[field] = df[field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[field] = df[field].str.replace(r\"http\", \"\")\n",
    "    df[field] = df[field].str.lower()\n",
    "    return df\n",
    "\n",
    "def dataPreprocessing(df):\n",
    "    df = df[df['ID'].notna()]\n",
    "    df = df[df['Barely True Cnt'].notna()]\n",
    "    df = df[df['False Cnt'].notna()]\n",
    "    df = df[df['Mostly True Cnt'].notna()]\n",
    "    df = df[df['Pants on Fire Cnt'].notna()]\n",
    "    df = df[df['Half True Cnt'].notna()]\n",
    "\n",
    "    df['ID'] = df['ID'].str.split(\".\", n = 1, expand = True) \n",
    "    \n",
    "    df = dataCleaning(df,'Statement')\n",
    "    df = dataCleaning(df,'Subject')\n",
    "    df = dataCleaning(df,'Speaker')\n",
    "    df = dataCleaning(df,'Job Title')\n",
    "    df = dataCleaning(df,'State')\n",
    "    df = dataCleaning(df,'Party')\n",
    "    df = dataCleaning(df,'Context')\n",
    "    df = dataCleaning(df,'Justification')    \n",
    "    \n",
    "    le_multi = LabelEncoder()\n",
    "    df.loc[:, 'Multi Class Label'] = le_multi.fit_transform(df.Label)\n",
    "    print(\"Label assignments: \" + str({l: i for i, l in enumerate(le_multi.classes_)}))   \n",
    "    \n",
    "    df['Binary Label'] = df.Label.apply(lambda x: 1 if x in ['false','pants-fire','barely-true']  else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label assignments: {'barely-true': 0, 'false': 1, 'half-true': 2, 'mostly-true': 3, 'pants-fire': 4, 'true': 5}\n"
     ]
    }
   ],
   "source": [
    "df_all = dataPreprocessing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Barely True Cnt</th>\n",
       "      <th>False Cnt</th>\n",
       "      <th>Half True Cnt</th>\n",
       "      <th>Mostly True Cnt</th>\n",
       "      <th>Pants on Fire Cnt</th>\n",
       "      <th>Context</th>\n",
       "      <th>Justification</th>\n",
       "      <th>train-test-val</th>\n",
       "      <th>Multi Class Label</th>\n",
       "      <th>Binary Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635</td>\n",
       "      <td>false</td>\n",
       "      <td>says the annies list political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne bohac</td>\n",
       "      <td>state representative</td>\n",
       "      <td>texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>that s a premise that he fails to back up  ann...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540</td>\n",
       "      <td>half-true</td>\n",
       "      <td>when did the decline of coal start  it started...</td>\n",
       "      <td>energy history job accomplishments</td>\n",
       "      <td>scott surovell</td>\n",
       "      <td>state delegate</td>\n",
       "      <td>virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech</td>\n",
       "      <td>surovell said the decline of coal  started whe...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>hillary clinton agrees with john mccain  by vo...</td>\n",
       "      <td>foreign policy</td>\n",
       "      <td>barack obama</td>\n",
       "      <td>president</td>\n",
       "      <td>illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>denver</td>\n",
       "      <td>obama said he would have voted against the ame...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123</td>\n",
       "      <td>false</td>\n",
       "      <td>health care reform legislation is likely to ma...</td>\n",
       "      <td>health care</td>\n",
       "      <td>blog posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "      <td>the release may have a point that mikulskis co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028</td>\n",
       "      <td>half-true</td>\n",
       "      <td>the economic turnaround started at the end of ...</td>\n",
       "      <td>economy jobs</td>\n",
       "      <td>charlie crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on cnn</td>\n",
       "      <td>crist said that the economic  turnaround start...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID        Label                                          Statement  \\\n",
       "0   2635        false  says the annies list political group supports ...   \n",
       "1  10540    half-true  when did the decline of coal start  it started...   \n",
       "2    324  mostly-true  hillary clinton agrees with john mccain  by vo...   \n",
       "3   1123        false  health care reform legislation is likely to ma...   \n",
       "4   9028    half-true  the economic turnaround started at the end of ...   \n",
       "\n",
       "                              Subject         Speaker             Job Title  \\\n",
       "0                            abortion    dwayne bohac  state representative   \n",
       "1  energy history job accomplishments  scott surovell        state delegate   \n",
       "2                      foreign policy    barack obama             president   \n",
       "3                         health care    blog posting                   NaN   \n",
       "4                        economy jobs   charlie crist                   NaN   \n",
       "\n",
       "      State       Party  Barely True Cnt  False Cnt  Half True Cnt  \\\n",
       "0     texas  republican              0.0        1.0            0.0   \n",
       "1  virginia    democrat              0.0        0.0            1.0   \n",
       "2  illinois    democrat             70.0       71.0          160.0   \n",
       "3       NaN        none              7.0       19.0            3.0   \n",
       "4   florida    democrat             15.0        9.0           20.0   \n",
       "\n",
       "   Mostly True Cnt  Pants on Fire Cnt              Context  \\\n",
       "0              0.0                0.0             a mailer   \n",
       "1              1.0                0.0      a floor speech    \n",
       "2            163.0                9.0               denver   \n",
       "3              5.0               44.0       a news release   \n",
       "4             19.0                2.0  an interview on cnn   \n",
       "\n",
       "                                       Justification  train-test-val  \\\n",
       "0  that s a premise that he fails to back up  ann...               0   \n",
       "1  surovell said the decline of coal  started whe...               0   \n",
       "2  obama said he would have voted against the ame...               0   \n",
       "3  the release may have a point that mikulskis co...               0   \n",
       "4  crist said that the economic  turnaround start...               0   \n",
       "\n",
       "   Multi Class Label  Binary Label  \n",
       "0                  1             1  \n",
       "1                  2             0  \n",
       "2                  3             0  \n",
       "3                  1             1  \n",
       "4                  2             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract out the required fields\n",
    "df = df_all[['Statement','train-test-val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom Statement to Unigram tokens\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df[\"Unigrams\"] = df[\"Statement\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT to download pretrained word2vec \n",
    "\n",
    "# import gensim.downloader as api\n",
    "# path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "# print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec_path = 'C:/Users/Nalin/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "word2vec_path = '/home/kalit/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "embedding_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert word representation using word embeddings\n",
    "def get_word2vec(unigrams, generate_missing=False, k=300):\n",
    "    if len(unigrams)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [embedding_model[word] if word in embedding_model else np.random.rand(k) for word in unigrams]\n",
    "    else:\n",
    "        vectorized = [embedding_model[word] if word in embedding_model else np.zeros(k) for word in unigrams]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(df, generate_missing=False):\n",
    "    embeddings = df['Unigrams'].apply(lambda x: get_word2vec(x,generate_missing=generate_missing))\n",
    "    return list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded_words = pd.DataFrame.from_records(get_word2vec_embeddings(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded_words[\"train-test-val\"] = df[\"train-test-val\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12789, 301)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedded_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training, validation and testing parts\n",
    "# Also, divide into input features and target labels\n",
    "\n",
    "df_y = df_all[['Binary Label','train-test-val']]\n",
    "\n",
    "x_train = df_embedded_words[df_embedded_words['train-test-val']==0]\n",
    "x_test = df_embedded_words[df_embedded_words['train-test-val']==1]\n",
    "x_val = df_embedded_words[df_embedded_words['train-test-val']==2]\n",
    "\n",
    "x_train.drop(['train-test-val'], axis = 1, inplace = True) \n",
    "x_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "x_val.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "\n",
    "y_train = df_y[df_y['train-test-val']==0]\n",
    "y_test = df_y[df_y['train-test-val']==1]\n",
    "y_val = df_y[df_y['train-test-val']==2]\n",
    "\n",
    "y_train.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_val.drop(['train-test-val'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(y_test,y_predict):\n",
    "    print(classification_report(y_test,y_predict))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_test,y_predict))\n",
    "    print(\"\\n Accuracy\")\n",
    "    print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63       714\n",
      "           1       0.54      0.59      0.56       553\n",
      "\n",
      "    accuracy                           0.60      1267\n",
      "   macro avg       0.59      0.60      0.59      1267\n",
      "weighted avg       0.60      0.60      0.60      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[433 281]\n",
      " [229 324]]\n",
      "\n",
      " Accuracy\n",
      "0.5974743488555643\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', random_state=30,C=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "# Results on testing data\n",
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62       668\n",
      "           1       0.60      0.64      0.62       616\n",
      "\n",
      "    accuracy                           0.62      1284\n",
      "   macro avg       0.62      0.62      0.62      1284\n",
      "weighted avg       0.62      0.62      0.62      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[403 265]\n",
      " [221 395]]\n",
      "\n",
      " Accuracy\n",
      "0.6214953271028038\n"
     ]
    }
   ],
   "source": [
    "# Results on validation data\n",
    "y_pred = model.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       714\n",
      "           1       0.60      0.20      0.29       553\n",
      "\n",
      "    accuracy                           0.59      1267\n",
      "   macro avg       0.60      0.55      0.50      1267\n",
      "weighted avg       0.59      0.59      0.53      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[642  72]\n",
      " [445 108]]\n",
      "\n",
      " Accuracy\n",
      "0.5919494869771112\n"
     ]
    }
   ],
   "source": [
    "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1)\n",
    "rbf.fit(x_train,y_train)\n",
    "y_pred = rbf.predict(x_test)\n",
    "\n",
    "# Results on testing data\n",
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       668\n",
      "           1       0.69      0.22      0.33       616\n",
      "\n",
      "    accuracy                           0.58      1284\n",
      "   macro avg       0.62      0.56      0.51      1284\n",
      "weighted avg       0.62      0.58      0.52      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[607  61]\n",
      " [480 136]]\n",
      "\n",
      " Accuracy\n",
      "0.5786604361370716\n"
     ]
    }
   ],
   "source": [
    "# Results on validation data\n",
    "y_pred = rbf.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       714\n",
      "           1       0.60      0.31      0.41       553\n",
      "\n",
      "    accuracy                           0.61      1267\n",
      "   macro avg       0.60      0.57      0.56      1267\n",
      "weighted avg       0.60      0.61      0.58      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[597 117]\n",
      " [381 172]]\n",
      "\n",
      " Accuracy\n",
      "0.6069455406471981\n"
     ]
    }
   ],
   "source": [
    "poly = svm.SVC(kernel='poly', degree=3, C=1)\n",
    "poly.fit(x_train,y_train)\n",
    "\n",
    "# Results on testing data\n",
    "y_pred = poly.predict(x_test)\n",
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70       668\n",
      "           1       0.71      0.36      0.48       616\n",
      "\n",
      "    accuracy                           0.62      1284\n",
      "   macro avg       0.65      0.61      0.59      1284\n",
      "weighted avg       0.65      0.62      0.59      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[576  92]\n",
      " [394 222]]\n",
      "\n",
      " Accuracy\n",
      "0.6214953271028038\n"
     ]
    }
   ],
   "source": [
    "# Results on validation data\n",
    "\n",
    "y_pred = poly.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training, validation and testing parts\n",
    "# Also, divide into input features and target labels\n",
    "\n",
    "df_y = df_all[['Multi Class Label','train-test-val']]\n",
    "\n",
    "x_train = df_embedded_words[df_embedded_words['train-test-val']==0]\n",
    "x_test = df_embedded_words[df_embedded_words['train-test-val']==1]\n",
    "x_val = df_embedded_words[df_embedded_words['train-test-val']==2]\n",
    "\n",
    "x_train.drop(['train-test-val'], axis = 1, inplace = True) \n",
    "x_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "x_val.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "\n",
    "y_train = df_y[df_y['train-test-val']==0]\n",
    "y_test = df_y[df_y['train-test-val']==1]\n",
    "y_val = df_y[df_y['train-test-val']==2]\n",
    "\n",
    "y_train.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_val.drop(['train-test-val'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.17      0.17       212\n",
      "           1       0.26      0.18      0.21       249\n",
      "           2       0.28      0.20      0.24       265\n",
      "           3       0.27      0.29      0.28       241\n",
      "           4       0.15      0.40      0.22        92\n",
      "           5       0.27      0.25      0.26       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.23      0.25      0.23      1267\n",
      "weighted avg       0.25      0.23      0.23      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[36 30 32 33 51 30]\n",
      " [50 45 27 44 57 26]\n",
      " [50 39 54 58 35 29]\n",
      " [33 23 42 71 27 45]\n",
      " [17  9 10  7 37 12]\n",
      " [23 30 25 46 32 52]]\n",
      "\n",
      " Accuracy\n",
      "0.23283346487766376\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', random_state=30,C=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "# Results on testing data\n",
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.19      0.21       237\n",
      "           1       0.19      0.14      0.16       263\n",
      "           2       0.27      0.17      0.21       248\n",
      "           3       0.26      0.24      0.25       251\n",
      "           4       0.19      0.45      0.27       116\n",
      "           5       0.23      0.33      0.27       169\n",
      "\n",
      "    accuracy                           0.23      1284\n",
      "   macro avg       0.23      0.25      0.23      1284\n",
      "weighted avg       0.23      0.23      0.22      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[45 40 29 44 48 31]\n",
      " [47 36 31 30 83 36]\n",
      " [38 45 43 53 34 35]\n",
      " [37 38 25 59 30 62]\n",
      " [18 19  3  6 52 18]\n",
      " [13 14 27 37 23 55]]\n",
      "\n",
      " Accuracy\n",
      "0.22585669781931464\n"
     ]
    }
   ],
   "source": [
    "# Results on validation data\n",
    "y_pred = model.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       212\n",
      "           1       0.24      0.39      0.30       249\n",
      "           2       0.22      0.65      0.32       265\n",
      "           3       0.29      0.08      0.13       241\n",
      "           4       0.00      0.00      0.00        92\n",
      "           5       0.00      0.00      0.00       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.13      0.19      0.13      1267\n",
      "weighted avg       0.15      0.23      0.15      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[  0  72 133   7   0   0]\n",
      " [  0  97 145   7   0   0]\n",
      " [  0  83 172  10   0   0]\n",
      " [  0  48 173  20   0   0]\n",
      " [  0  45  43   4   0   0]\n",
      " [  0  57 131  20   0   0]]\n",
      "\n",
      " Accuracy\n",
      "0.2280978689818469\n"
     ]
    }
   ],
   "source": [
    "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1)\n",
    "rbf.fit(x_train,y_train)\n",
    "y_pred = rbf.predict(x_test)\n",
    "\n",
    "# Results on testing data\n",
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       237\n",
      "           1       0.28      0.43      0.34       263\n",
      "           2       0.21      0.66      0.31       248\n",
      "           3       0.31      0.10      0.16       251\n",
      "           4       0.00      0.00      0.00       116\n",
      "           5       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.24      1284\n",
      "   macro avg       0.13      0.20      0.13      1284\n",
      "weighted avg       0.16      0.24      0.16      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[  0  73 156   8   0   0]\n",
      " [  0 112 139  12   0   0]\n",
      " [  0  67 164  17   0   0]\n",
      " [  0  58 167  26   0   0]\n",
      " [  0  59  55   2   0   0]\n",
      " [  0  36 115  18   0   0]]\n",
      "\n",
      " Accuracy\n",
      "0.235202492211838\n"
     ]
    }
   ],
   "source": [
    "# Results on validation data\n",
    "y_pred = rbf.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.13      0.18       212\n",
      "           1       0.28      0.28      0.28       249\n",
      "           2       0.24      0.48      0.32       265\n",
      "           3       0.26      0.32      0.29       241\n",
      "           4       0.18      0.04      0.07        92\n",
      "           5       0.21      0.07      0.11       208\n",
      "\n",
      "    accuracy                           0.25      1267\n",
      "   macro avg       0.24      0.22      0.21      1267\n",
      "weighted avg       0.25      0.25      0.23      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 28  44  91  35   3  11]\n",
      " [ 24  70  85  53   5  12]\n",
      " [ 25  46 127  56   4   7]\n",
      " [  6  25 108  77   3  22]\n",
      " [ 11  27  33  12   4   5]\n",
      " [ 12  40  78  60   3  15]]\n",
      "\n",
      " Accuracy\n",
      "0.2533543804262036\n"
     ]
    }
   ],
   "source": [
    "poly = svm.SVC(kernel='poly', degree=3, C=1)\n",
    "poly.fit(x_train,y_train)\n",
    "\n",
    "# Results on testing data\n",
    "y_pred = poly.predict(x_test)\n",
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.09      0.13       237\n",
      "           1       0.30      0.29      0.29       263\n",
      "           2       0.23      0.52      0.32       248\n",
      "           3       0.23      0.24      0.24       251\n",
      "           4       0.27      0.06      0.10       116\n",
      "           5       0.23      0.11      0.15       169\n",
      "\n",
      "    accuracy                           0.24      1284\n",
      "   macro avg       0.25      0.22      0.21      1284\n",
      "weighted avg       0.25      0.24      0.22      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 22  45 112  41   5  12]\n",
      " [ 28  76  94  40   9  16]\n",
      " [ 17  36 129  55   0  11]\n",
      " [ 12  45 110  61   1  22]\n",
      " [ 12  38  45  10   7   4]\n",
      " [ 10  17  66  53   4  19]]\n",
      "\n",
      " Accuracy\n",
      "0.24454828660436137\n"
     ]
    }
   ],
   "source": [
    "# Results on validation data\n",
    "\n",
    "y_pred = poly.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
