{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report,accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import svm\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade gensim==3.8.3\n",
    "#!pip3 install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all three datasets\n",
    "trainFilePath = 'dataset/train2.tsv'\n",
    "testFilePath = 'dataset/test2.tsv'\n",
    "validationFilePath = 'dataset/val2.tsv'\n",
    "\n",
    "# add header to all three datasets\n",
    "df_train = pd.read_csv(trainFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
    "\n",
    "df_test = pd.read_csv(testFilePath, delimiter='\\t',  names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])\n",
    "\n",
    "\n",
    "df_validation = pd.read_csv(validationFilePath, delimiter='\\t', names=[\"ID\", \"Label\", \"Statement\", \"Subject\", \"Speaker\", \"Job Title\", \"State\", \"Party\",\n",
    "                         \"Barely True Cnt\", \"False Cnt\", \"Half True Cnt\", \"Mostly True Cnt\", \"Pants on Fire Cnt\", \"Context\", \"Justification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"train-test-val\"] = 0\n",
    "df_test[\"train-test-val\"] = 1\n",
    "df_validation[\"train-test-val\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train,df_test,df_validation]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleaning(df,field):\n",
    "    df[field] = df[field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[field] = df[field].str.replace(r\"[^A-Za-z0-9]\", \" \")\n",
    "    df[field] = df[field].str.replace(r\"(),!?@\\'\\`\\\"\\_\\n\", \" \")\n",
    "    df[field] = df[field].str.replace(r\"@\", \"at\")\n",
    "    df[field] = df[field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[field] = df[field].str.replace(r\"http\", \"\")\n",
    "    df[field] = df[field].str.lower()\n",
    "    df[field].fillna('', inplace=True)\n",
    "    return df\n",
    "\n",
    "def dataPreprocessing(df):\n",
    "    df = df[df['ID'].notna()]\n",
    "    df = df[df['Barely True Cnt'].notna()]\n",
    "    df = df[df['False Cnt'].notna()]\n",
    "    df = df[df['Mostly True Cnt'].notna()]\n",
    "    df = df[df['Pants on Fire Cnt'].notna()]\n",
    "    df = df[df['Half True Cnt'].notna()]\n",
    "\n",
    "    df['ID'] = df['ID'].str.split(\".\", n = 1, expand = True) \n",
    "    \n",
    "    df = dataCleaning(df,'Statement')\n",
    "    df = dataCleaning(df,'Subject')\n",
    "    df = dataCleaning(df,'Speaker')\n",
    "    df = dataCleaning(df,'Job Title')\n",
    "    df = dataCleaning(df,'State')\n",
    "    df = dataCleaning(df,'Party')\n",
    "    df = dataCleaning(df,'Context')\n",
    "    df = dataCleaning(df,'Justification')    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = dataPreprocessing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Barely True Cnt</th>\n",
       "      <th>False Cnt</th>\n",
       "      <th>Half True Cnt</th>\n",
       "      <th>Mostly True Cnt</th>\n",
       "      <th>Pants on Fire Cnt</th>\n",
       "      <th>Context</th>\n",
       "      <th>Justification</th>\n",
       "      <th>train-test-val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635</td>\n",
       "      <td>false</td>\n",
       "      <td>says the annies list political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne bohac</td>\n",
       "      <td>state representative</td>\n",
       "      <td>texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>that s a premise that he fails to back up  ann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540</td>\n",
       "      <td>half-true</td>\n",
       "      <td>when did the decline of coal start  it started...</td>\n",
       "      <td>energy history job accomplishments</td>\n",
       "      <td>scott surovell</td>\n",
       "      <td>state delegate</td>\n",
       "      <td>virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech</td>\n",
       "      <td>surovell said the decline of coal  started whe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>hillary clinton agrees with john mccain  by vo...</td>\n",
       "      <td>foreign policy</td>\n",
       "      <td>barack obama</td>\n",
       "      <td>president</td>\n",
       "      <td>illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>denver</td>\n",
       "      <td>obama said he would have voted against the ame...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123</td>\n",
       "      <td>false</td>\n",
       "      <td>health care reform legislation is likely to ma...</td>\n",
       "      <td>health care</td>\n",
       "      <td>blog posting</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "      <td>the release may have a point that mikulskis co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028</td>\n",
       "      <td>half-true</td>\n",
       "      <td>the economic turnaround started at the end of ...</td>\n",
       "      <td>economy jobs</td>\n",
       "      <td>charlie crist</td>\n",
       "      <td></td>\n",
       "      <td>florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on cnn</td>\n",
       "      <td>crist said that the economic  turnaround start...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID        Label                                          Statement  \\\n",
       "0   2635        false  says the annies list political group supports ...   \n",
       "1  10540    half-true  when did the decline of coal start  it started...   \n",
       "2    324  mostly-true  hillary clinton agrees with john mccain  by vo...   \n",
       "3   1123        false  health care reform legislation is likely to ma...   \n",
       "4   9028    half-true  the economic turnaround started at the end of ...   \n",
       "\n",
       "                              Subject         Speaker             Job Title  \\\n",
       "0                            abortion    dwayne bohac  state representative   \n",
       "1  energy history job accomplishments  scott surovell        state delegate   \n",
       "2                      foreign policy    barack obama             president   \n",
       "3                         health care    blog posting                         \n",
       "4                        economy jobs   charlie crist                         \n",
       "\n",
       "      State       Party  Barely True Cnt  False Cnt  Half True Cnt  \\\n",
       "0     texas  republican              0.0        1.0            0.0   \n",
       "1  virginia    democrat              0.0        0.0            1.0   \n",
       "2  illinois    democrat             70.0       71.0          160.0   \n",
       "3                  none              7.0       19.0            3.0   \n",
       "4   florida    democrat             15.0        9.0           20.0   \n",
       "\n",
       "   Mostly True Cnt  Pants on Fire Cnt              Context  \\\n",
       "0              0.0                0.0             a mailer   \n",
       "1              1.0                0.0      a floor speech    \n",
       "2            163.0                9.0               denver   \n",
       "3              5.0               44.0       a news release   \n",
       "4             19.0                2.0  an interview on cnn   \n",
       "\n",
       "                                       Justification  train-test-val  \n",
       "0  that s a premise that he fails to back up  ann...               0  \n",
       "1  surovell said the decline of coal  started whe...               0  \n",
       "2  obama said he would have voted against the ame...               0  \n",
       "3  the release may have a point that mikulskis co...               0  \n",
       "4  crist said that the economic  turnaround start...               0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_all[['Label','train-test-val']]\n",
    "encoder= ce.OrdinalEncoder(cols=['Label'],return_df=True,\n",
    "                           mapping=[{'col':'Label',\n",
    "'mapping':{'pants-fire':0,'false':0,'barely-true':0,'half-true':1,'mostly-true':1,'true':1}}])\n",
    "df_y = encoder.fit_transform(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all[['Label','Statement','Justification','train-test-val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom Statement to Unigram tokens\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df[\"Statement-Unigrams\"] = df[\"Statement\"].apply(tokenizer.tokenize)\n",
    "df[\"Justification-Unigrams\"] = df[\"Justification\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT to download pretrained word2vec \n",
    "\n",
    "# import gensim.downloader as api\n",
    "# path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "# print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec_path = 'C:/Users/Nalin/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "word2vec_path = '/home/kalit/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec(unigrams, generate_missing=False, k=300):\n",
    "    if len(unigrams)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [model[word] if word in model else np.random.rand(k) for word in unigrams]\n",
    "    else:\n",
    "        vectorized = [model[word] if word in model else np.zeros(k) for word in unigrams]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(df,field, generate_missing=False):\n",
    "    embeddings = df[field].apply(lambda x: get_word2vec(x,generate_missing=generate_missing))\n",
    "    return list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_statement = get_word2vec_embeddings(df,'Statement-Unigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_justification = get_word2vec_embeddings(df,'Justification-Unigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded_statement = pd.DataFrame.from_records(embeddings_statement) \n",
    "df_embedded_justification = pd.DataFrame.from_records(embeddings_justification) \n",
    "df_embedded = pd.concat([df_embedded_statement,df_embedded_justification],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded[\"train-test-val\"] = df[\"train-test-val\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_embedded[df_embedded['train-test-val']==0]\n",
    "x_test = df_embedded[df_embedded['train-test-val']==1]\n",
    "x_val = df_embedded[df_embedded['train-test-val']==2]\n",
    "\n",
    "x_train.drop(['train-test-val'], axis = 1, inplace = True) \n",
    "x_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "x_val.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "\n",
    "y_train = df_y[df_y['train-test-val']==0]\n",
    "y_test = df_y[df_y['train-test-val']==1]\n",
    "y_val = df_y[df_y['train-test-val']==2]\n",
    "\n",
    "y_train.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_test.drop(['train-test-val'], axis = 1, inplace = True)\n",
    "y_val.drop(['train-test-val'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train: 10238\n",
      "Y-Train: 10238\n",
      "X-Test: 1267\n",
      "Y-Test: 1267\n",
      "X-val: 1284\n",
      "Y-val: 1284\n"
     ]
    }
   ],
   "source": [
    "print(\"X-Train: \"+str(len(x_train)))\n",
    "print(\"Y-Train: \"+str(len(y_train)))\n",
    "print(\"X-Test: \"+str(len(x_test)))\n",
    "print(\"Y-Test: \"+str(len(y_test)))\n",
    "print(\"X-val: \"+str(len(x_val)))\n",
    "print(\"Y-val: \"+str(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', random_state=30)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(y_test,y_predict):\n",
    "    print(classification_report(y_test,y_predict))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_test,y_predict))\n",
    "    print(\"\\n Accuracy\")\n",
    "    print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.59      0.56       553\n",
      "           1       0.66      0.61      0.63       714\n",
      "\n",
      "    accuracy                           0.60      1267\n",
      "   macro avg       0.60      0.60      0.60      1267\n",
      "weighted avg       0.61      0.60      0.60      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[328 225]\n",
      " [282 432]]\n",
      "\n",
      " Accuracy\n",
      "0.5998421468034728\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62       616\n",
      "           1       0.65      0.63      0.64       668\n",
      "\n",
      "    accuracy                           0.63      1284\n",
      "   macro avg       0.63      0.63      0.63      1284\n",
      "weighted avg       0.63      0.63      0.63      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[390 226]\n",
      " [245 423]]\n",
      "\n",
      " Accuracy\n",
      "0.633177570093458\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf.fit(x_train,y_train)\n",
    "y_pred = rbf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.15      0.24       553\n",
      "           1       0.58      0.91      0.71       714\n",
      "\n",
      "    accuracy                           0.58      1267\n",
      "   macro avg       0.58      0.53      0.48      1267\n",
      "weighted avg       0.58      0.58      0.51      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 85 468]\n",
      " [ 62 652]]\n",
      "\n",
      " Accuracy\n",
      "0.5816890292028414\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.21      0.32       616\n",
      "           1       0.56      0.92      0.69       668\n",
      "\n",
      "    accuracy                           0.58      1284\n",
      "   macro avg       0.62      0.56      0.50      1284\n",
      "weighted avg       0.62      0.58      0.51      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[127 489]\n",
      " [ 56 612]]\n",
      "\n",
      " Accuracy\n",
      "0.5755451713395638\n"
     ]
    }
   ],
   "source": [
    "y_pred = rbf.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.fit(x_train,y_train)\n",
    "y_pred = poly.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.34      0.44       553\n",
      "           1       0.62      0.83      0.71       714\n",
      "\n",
      "    accuracy                           0.62      1267\n",
      "   macro avg       0.61      0.59      0.57      1267\n",
      "weighted avg       0.62      0.62      0.59      1267\n",
      "\n",
      "Confusion Matrix\n",
      "[[189 364]\n",
      " [121 593]]\n",
      "\n",
      " Accuracy\n",
      "0.6172059984214681\n"
     ]
    }
   ],
   "source": [
    "printResults(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.38      0.49       616\n",
      "           1       0.60      0.85      0.70       668\n",
      "\n",
      "    accuracy                           0.62      1284\n",
      "   macro avg       0.65      0.61      0.59      1284\n",
      "weighted avg       0.64      0.62      0.60      1284\n",
      "\n",
      "Confusion Matrix\n",
      "[[232 384]\n",
      " [101 567]]\n",
      "\n",
      " Accuracy\n",
      "0.6222741433021807\n"
     ]
    }
   ],
   "source": [
    "y_pred = poly.predict(x_val)\n",
    "printResults(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
